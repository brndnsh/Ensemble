import { ACTIONS } from './types.js';
import { playback, groove, chords, bass, soloist, harmony, arranger, vizState, dispatch } from './state.js';
import { triggerFlash } from './ui.js';
import { initAudio, playNote, playDrumSound, playBassNote, playSoloNote, playHarmonyNote, killHarmonyNote, updateSustain, restoreGains, killAllNotes } from './engine.js';
import { TIME_SIGNATURES } from './config.js';
import { getStepsPerMeasure, getStepInfo, getMidi, midiToNote } from './utils.js';
import { requestBuffer, syncWorker, flushWorker, stopWorker, startWorker, requestResolution } from './worker-client.js';
import { conductorState, updateAutoConductor, updateLarsTempo, checkSectionTransition } from './conductor.js';
import { applyGrooveOverrides, calculatePocketOffset } from './groove-engine.js';
import { loadDrumPreset, flushBuffers } from './instrument-controller.js';
import { draw } from './animation-loop.js';
import { sendMIDINote, sendMIDIDrum, sendMIDICC, normalizeMidiVelocity, panic, sendMIDITransport } from './midi-controller.js';
import { midi as midiState } from './state.js';
import { initPlatform, unlockAudio, lockAudio, activateWakeLock, deactivateWakeLock } from './platform.js';

const DRUM_VIS_PITCHES = {
    'Kick': 36, 'Snare': 38, 'HiHat': 42, 'ClosedHat': 42, 'Open': 46, 'OpenHat': 46,
    'Ride': 51, 'Crash': 49, 'TomHi': 50, 'TomMid': 47, 'TomLow': 45,
    'Rimshot': 37, 'Clap': 39, 'Shaker': 70, 'Cowbell': 56
};

let isScheduling = false;
let isResolutionTriggered = false;

// Initialize platform-specific hacks (iOS Audio, WakeLock state)
initPlatform();

export function togglePlay(viz) {
    const activeViz = viz || playback.viz;
    if (playback.isPlaying) {
        playback.isPlaying = false;
        stopWorker();
        lockAudio();
        deactivateWakeLock();
        playback.drawQueue = [];
        playback.lastActiveDrumElements = null;
        chords.lastActiveChordIndex = null;
        if (activeViz) activeViz.clear();
        dispatch('VIS_RESET');
        killAllNotes();
        panic(true); // Full MIDI reset
        sendMIDITransport('stop', playback.audio.currentTime);
        flushBuffers();
        
        if (playback.audio) {
            if (playback.suspendTimeout) clearTimeout(playback.suspendTimeout);
            playback.suspendTimeout = setTimeout(() => {
                if (!playback.isPlaying && playback.audio.state === 'running') playback.audio.suspend();
            }, 3000); 
        }
    } else {
        if (playback.suspendTimeout) clearTimeout(playback.suspendTimeout);
        initAudio();
        
        if (playback.audio && playback.audio.state === 'suspended') {
            playback.audio.resume();
        }

        playback.isPlaying = true;
        playback.step = 0;
        isResolutionTriggered = false;
        dispatch(ACTIONS.RESET_SESSION); // Reset warm-up counters
        dispatch(ACTIONS.SET_ENDING_PENDING, false);
        playback.sessionStartTime = performance.now();
        syncWorker(); 
        const primeSteps = (arranger.totalSteps > 0) ? arranger.totalSteps * 2 : 0;
        flushBuffers(primeSteps);
        
        unlockAudio();
        restoreGains();
        const startTime = playback.audio.currentTime + 0.1;
        playback.nextNoteTime = startTime;
        playback.unswungNextNoteTime = startTime;
        playback.isCountingIn = playback.countIn;
        playback.countInBeat = 0;
        activateWakeLock();
        if (activeViz) activeViz.setBeatReference(playback.nextNoteTime);
        if (!playback.isDrawing) {
            playback.isDrawing = true;
            requestAnimationFrame(() => draw(activeViz));
        }
        
        // Initial MIDI cleanup
        panic(true);
        sendMIDITransport('start', startTime);

        startWorker();
        scheduler();
    }
}

function triggerResolution(time) {
    // 1. Tell worker to generate resolution
    requestResolution(playback.step);

    // 2. We'll wait for the notes to come back via the worker-client callback
    // The worker-client already handles incoming 'notes' and puts them in buffers.
    // We just need to wait a few ms and then schedule them.
    setTimeout(() => {
        scheduleResolution(time);
    }, 50);
}

function scheduleResolution(time) {
    // Schedule the final resolution measure (Tonic chord, Kick+Crash, etc.)
    const effectiveBpm = playback.bpm + (conductorState.larsBpmOffset || 0);
    const spb = 60.0 / effectiveBpm;
    const measureDuration = 8 * spb; // Ring out for 2 bars (approx 5-6s)

    // 1. Schedule all instruments that came from the worker (Bass, Chords, Soloist, Harmony, Groove)
    // The worker-client puts these in track buffers.
    // Create a dummy chord data for visuals
    const dummyChordData = { chord: { freqs: [] } };
    
    if (bass.enabled) scheduleBass(dummyChordData, playback.step, time);
    if (soloist.enabled) scheduleSoloist(dummyChordData, playback.step, time, time);
    if (chords.enabled) scheduleChords(dummyChordData, playback.step, time);
    if (harmony.enabled) scheduleHarmonies(dummyChordData, playback.step, time);
    if (groove.enabled) scheduleDrumsFromBuffer(playback.step, time);
    
    // 2. Add a final flash
    if (playback.visualFlash) {
        triggerFlash(0.4);
    }

    // 3. Graceful Sustain Release (at 1.5 bars)
    setTimeout(() => {
        if (playback.isPlaying) updateSustain(false);
    }, 6 * spb * 1000);

    // 4. Stop playback after the full ring-out (2 bars)
    setTimeout(() => {
        if (playback.isPlaying) togglePlay(); 
    }, measureDuration * 1000);
}

export function scheduler() {
    if (isScheduling) return;
    isScheduling = true;

    try {
        requestBuffer(playback.step);
        
        // Update genre UI (countdowns)
        if (groove.pendingGenreFeel) {
            const stepsPerMeasure = getStepsPerMeasure(arranger.timeSignature);
            const stepsRemaining = stepsPerMeasure - (playback.step % stepsPerMeasure);
            if (stepsRemaining > 0 && stepsRemaining <= 16) {
                // Pre-notify for genre changes
            }
        }

        while (playback.nextNoteTime < playback.audio.currentTime + playback.scheduleAheadTime) {
            if (playback.isCountingIn) {
                scheduleCountIn(playback.countInBeat, playback.nextNoteTime);
                advanceCountIn();
            } else {
                const spm = getStepsPerMeasure(arranger.timeSignature);
                
                // --- Session Timer Check ---
                if (playback.sessionTimer > 0 && !playback.isEndingPending) {
                    const elapsedMins = (performance.now() - playback.sessionStartTime) / 60000;
                    if (elapsedMins >= playback.sessionTimer) {
                        dispatch(ACTIONS.SET_ENDING_PENDING, true);
                    }
                }

                // --- Resolution Trigger Logic ---
                // If ending is pending or stopAtEnd is active, and we reach a loop boundary (Step 0)
                if (playback.step > 0 && (playback.step % arranger.totalSteps === 0)) {
                    if (playback.isEndingPending || playback.stopAtEnd || isResolutionTriggered) {
                        if (!isResolutionTriggered) {
                            isResolutionTriggered = true;
                            playback.stopAtEnd = false;
                            triggerResolution(playback.nextNoteTime);
                        }
                        return; // Stop scheduling
                    }
                }

                if (playback.step % spm === 0 && groove.pendingGenreFeel) {
                    applyPendingGenre();
                }

                scheduleGlobalEvent(playback.step, playback.nextNoteTime);
                advanceGlobalStep();
            }
        }
    } finally {
        isScheduling = false;
    }
}

function applyPendingGenre() {
    const payload = groove.pendingGenreFeel;
    if (!payload) return;

    groove.genreFeel = payload.feel;
    if (payload.swing !== undefined) groove.swing = payload.swing;
    if (payload.sub !== undefined) groove.swingSub = payload.sub;
    if (payload.genreName) groove.lastSmartGenre = payload.genreName;
    
    if (payload.drum) {
        loadDrumPreset(payload.drum);
    }

    groove.pendingGenreFeel = null;
    
    playback.nextNoteTime = playback.unswungNextNoteTime;

    syncAndFlushWorker(playback.step);
    triggerFlash(0.15);
}

function advanceCountIn() {
    const effectiveBpm = playback.bpm + (conductorState.larsBpmOffset || 0);
    const beatDuration = 60.0 / effectiveBpm;
    playback.nextNoteTime += beatDuration;
    playback.unswungNextNoteTime += beatDuration;
    playback.countInBeat++;
    const ts = TIME_SIGNATURES[arranger.timeSignature] || TIME_SIGNATURES['4/4'];
    if (playback.countInBeat >= ts.beats) {
        playback.isCountingIn = false;
        playback.step = 0; 
    }
}

function scheduleCountIn(beat, time) {
     if (playback.visualFlash) playback.drawQueue.push({ type: 'flash', time: time, intensity: 0.3, beat: 1 });
     const osc = playback.audio.createOscillator();
     const gain = playback.audio.createGain();
     osc.connect(gain);
     gain.connect(playback.masterGain);
     const ts = TIME_SIGNATURES[arranger.timeSignature] || TIME_SIGNATURES['4/4'];
     let freq = 440;
     if (beat === 0) freq = 1000;
     else if (ts.grouping && ts.grouping.length > 1) {
         let accumulated = 0;
         for (let g of ts.grouping) {
             if (beat === accumulated && beat !== 0) { freq = 800; break; }
             accumulated += g;
         }
     } else {
         if (beat === 0) freq = 1000;
         else if (arranger.timeSignature === '4/4' && beat === 2) freq = 800;
         else if (arranger.timeSignature === '6/8' && beat === 3) freq = 800;
         else if (arranger.timeSignature === '12/8' && (beat === 3 || beat === 6 || beat === 9)) freq = 800;
     }
     osc.frequency.setValueAtTime(freq, time);
     gain.gain.setValueAtTime(0.3, time);
     gain.gain.exponentialRampToValueAtTime(0.001, time + 0.1);
     osc.onended = () => { gain.disconnect(); osc.disconnect(); };
     osc.start(time);
     osc.stop(time + 0.1);
}

function advanceGlobalStep() {
    updateLarsTempo(playback.step);
    const effectiveBpm = playback.bpm + (conductorState.larsBpmOffset || 0);
    const sixteenth = 0.25 * (60.0 / effectiveBpm);
    let duration = sixteenth;
    if (groove.swing > 0) {
        // Find current time signature for swing logic
        const sInfo = getStepInfo(playback.step, TIME_SIGNATURES[arranger.timeSignature] || TIME_SIGNATURES['4/4'], arranger.measureMap, TIME_SIGNATURES);
        const ts = TIME_SIGNATURES[sInfo.tsName] || TIME_SIGNATURES['4/4'];
        if (ts.stepsPerBeat === 4) {
            const shift = (sixteenth / 3) * (groove.swing / 100);
            duration += (groove.swingSub === '16th') ? ((playback.step % 2 === 0) ? shift : -shift) : (((playback.step % 4) < 2) ? shift : -shift);
        }
    }
    playback.nextNoteTime += duration;
    playback.unswungNextNoteTime += sixteenth;
    playback.step++;
}

function getChordAtStep(step) {
    if (arranger.totalSteps === 0) return null;
    const targetStep = step % arranger.totalSteps;
    for (let i = 0; i < arranger.stepMap.length; i++) {
        const entry = arranger.stepMap[i];
        if (targetStep >= entry.start && targetStep < entry.end) {
            return { chord: entry.chord, stepInChord: targetStep - entry.start, chordIndex: i };
        }
    }
    return null;
}

export function scheduleDrums(step, time, isDownbeat, isQuarter, isBackbeat, absoluteStep, isGroupStart) {
    const conductorVel = playback.conductorVelocity || 1.0;
    const finalTime = time + calculatePocketOffset(playback, groove);

    const header = document.querySelector('.groove-panel-header h2');
    if (header) header.style.color = groove.fillActive ? 'var(--soloist-color)' : '';
    
    if (groove.fillActive) {
        const fillStep = absoluteStep - groove.fillStartStep;
        if (fillStep >= groove.fillLength) {
            groove.fillActive = false;
            if (groove.pendingCrash) { playDrumSound('Crash', finalTime, 1.1 * conductorVel); groove.pendingCrash = false; }
        }
    }
    
    if (groove.fillActive) {
        const fillStep = absoluteStep - groove.fillStartStep;
        if (fillStep >= 0 && fillStep < groove.fillLength) {
            if (playback.bandIntensity >= 0.5 || fillStep >= (groove.fillLength / 2)) {
                const notes = groove.fillSteps[fillStep];
                if (notes && notes.length > 0) {
                    if (vizState.enabled && playback.viz) {
                        playback.drawQueue.push({ type: 'fill_active', time: finalTime, active: true });
                    }
                    notes.forEach(note => {
                        playDrumSound(note.name, finalTime, note.vel * conductorVel);
                        
                        if (vizState.enabled && playback.viz) {
                            const midi = DRUM_VIS_PITCHES[note.name] || 36;
                            playback.drawQueue.push({ 
                                type: 'drums_vis', 
                                midi, 
                                time: finalTime, 
                                velocity: note.vel * conductorVel,
                                duration: 0.1
                            });
                        }
                    });
                    return;
                }
            }
        }
    } else if (vizState.enabled && playback.viz) {
        // Ensure fill visual state is cleared when fill is not active
        playback.drawQueue.push({ type: 'fill_active', time: finalTime, active: false });
    }

    groove.instruments.forEach(inst => {
        const { shouldPlay, velocity, soundName, instTimeOffset } = applyGrooveOverrides({
            step, inst, stepVal: inst.steps[step], playback, groove, isDownbeat, isQuarter, isBackbeat, isGroupStart
        });

                if (shouldPlay && !inst.muted) {
                    const playTime = finalTime + instTimeOffset;
                    playDrumSound(soundName, playTime, velocity * conductorVel);
                    
                    if (vizState.enabled && playback.viz) {
                        const midi = DRUM_VIS_PITCHES[soundName] || 36;
                        playback.drawQueue.push({ 
                            type: 'drums_vis', 
                            midi, 
                            time: playTime, 
                            velocity: velocity * conductorVel,
                            duration: 0.1
                        });
                    }

                    sendMIDIDrum(soundName, playTime, Math.min(1.0, velocity * conductorVel), midiState.drumsOctave);
                }
    });
}

export function scheduleDrumsFromBuffer(step, time) {
    const notes = groove.buffer.get(step);
    groove.buffer.delete(step);
    
    if (notes && notes.length > 0) {
        const conductorVel = playback.conductorVelocity || 1.0;

        notes.forEach(n => {
            const { name, velocity, timingOffset } = n;
            const playTime = time + (timingOffset || 0);
            
            playDrumSound(name, playTime, velocity * conductorVel);
            
            if (vizState.enabled && playback.viz) {
                const midi = DRUM_VIS_PITCHES[name] || 36;
                playback.drawQueue.push({ 
                    type: 'drums_vis', 
                    midi, 
                    time: playTime, 
                    velocity: velocity * conductorVel,
                    duration: 0.1
                });
            }

            sendMIDIDrum(name, playTime, Math.min(1.0, velocity * conductorVel), midiState.drumsOctave);
        });
    }
}

export function scheduleBass(chordData, step, time) {
    const noteEntry = bass.buffer.get(step);
    bass.buffer.delete(step);
    if (noteEntry && noteEntry.freq) {
        const { freq, durationSteps, velocity, timingOffset, muted } = noteEntry; 
        const { chord } = chordData;
        const adjustedTime = time + (timingOffset || 0);
        bass.lastPlayedFreq = freq;
        const midi = getMidi(freq);
        const { name, octave } = midiToNote(midi);
        const spb = 60.0 / playback.bpm;
        const duration = (durationSteps || 4) * 0.25 * spb;
        const finalVel = (velocity || 1.0) * (playback.conductorVelocity || 1.0);
        if (vizState.enabled && playback.viz) {
            playback.viz.truncateNotes('bass', adjustedTime);
            playback.drawQueue.push({ type: 'bass_vis', name, octave, midi, time: adjustedTime, chordNotes: chord.freqs.map(f => getMidi(f)), duration });
        }
        playBassNote(freq, adjustedTime, duration, finalVel, muted);
        if (!muted) {
            // Bass is strictly monophonic, so we force Mono mode to kill previous notes
            sendMIDINote(midiState.bassChannel, midi + (midiState.bassOctave * 12), normalizeMidiVelocity(finalVel), adjustedTime, duration, true);
        }
    }
}

export function scheduleSoloist(chordData, step, time, unswungTime) {
    const notes = soloist.buffer.get(step);
    soloist.buffer.delete(step);
    
    if (notes && notes.length > 0) {
        // Optimization: Avoid allocation if we only play one note (Common case)
        let notesToPlay = notes;
        if (!soloist.doubleStops && notes.length > 1) {
             notesToPlay = [notes[0]];
        }
        
        // Power-compensation for double stops: Scale volume by 1/sqrt(N)
        let numVoices = 0;
        for (let i = 0; i < notesToPlay.length; i++) {
            if (notesToPlay[i].freq) numVoices++;
        }
        const polyphonyComp = 1 / Math.sqrt(Math.max(1, numVoices));

        notesToPlay.forEach(noteEntry => {
            if (noteEntry && noteEntry.freq) {
                const { freq, durationSteps, velocity, bendStartInterval, style, timingOffset, noteType } = noteEntry;
                const { chord } = chordData;
                const offsetS = (timingOffset || 0); 
                
                if (!noteEntry.isDoubleStop) {
                    soloist.lastPlayedFreq = freq;
                }
                
                const midi = noteEntry.midi || getMidi(freq);
                const { name, octave } = midiToNote(midi);
                const spb = 60.0 / playback.bpm;
                const duration = (durationSteps || 4) * 0.25 * spb;
                const baseVel = (velocity || 1.0) * (playback.conductorVelocity || 1.0);
                const vel = baseVel * polyphonyComp;
                const playTime = unswungTime + offsetS;
                
                playSoloNote(freq, playTime, duration, vel, bendStartInterval || 0, style);
                
                // Soloist is monophonic UNLESS double stops are enabled
                const isMono = !soloist.doubleStops;
                
                // Support Pitch Bend for MIDI scoops
                let bend = 0;
                if (bendStartInterval !== 0) {
                    // Map semitones to 14-bit value (-8192 to 8191)
                    // Assuming standard 2-semitone range.
                    bend = Math.round(-(bendStartInterval / 2) * 8192);
                }

                sendMIDINote(midiState.soloistChannel, midi + (midiState.soloistOctave * 12), normalizeMidiVelocity(vel), playTime, duration, { isMono, bend });
                
                if (vizState.enabled && playback.viz) {
                    if (isMono) {
                        playback.viz.truncateNotes('soloist', playTime);
                    }
                    playback.drawQueue.push({ type: 'soloist_vis', name, octave, midi, time: playTime, chordNotes: chord.freqs.map(f => getMidi(f)), duration, noteType });
                }
                soloist.lastNoteEnd = playTime + duration;
            }
        });
    }
}

export function scheduleChordVisuals(chordData, t) {
    if (chordData.stepInChord === 0) {
        playback.drawQueue.push({ type: 'chord_vis', time: t, index: chordData.chordIndex, chordNotes: chordData.chord.freqs.map(f => getMidi(f)), rootMidi: chordData.chord.rootMidi, intervals: chordData.chord.intervals, duration: chordData.chord.beats * (60/playback.bpm) });
        
        if (playback.visualFlash) {
            triggerFlash(0.1);
        }
    }
}

export function scheduleChords(chordData, step, time) {
    const notes = chords.buffer.get(step);
    chords.buffer.delete(step);
    
    if (notes && notes.length > 0) {
        const spb = 60.0 / playback.bpm;
        // Count how many non-muted notes are in this step for volume normalization
        let numVoices = 0;
        for (let i = 0; i < notes.length; i++) {
            if (!notes[i].muted && notes[i].freq) numVoices++;
        }

        notes.forEach(n => {
            const { freq, velocity, timingOffset, durationSteps, muted, instrument, dry, ccEvents } = n;
            const playTime = time + (timingOffset || 0);

            if (ccEvents && ccEvents.length > 0) {
                ccEvents.forEach(cc => {
                   if (cc.controller === 64) {
                       const isSustain = cc.value >= 64;
                       const ccTime = playTime + (cc.timingOffset || 0); 
                       updateSustain(isSustain, ccTime);
                       sendMIDICC(midiState.chordsChannel, 64, cc.value, ccTime);
                   }
               });
            }

            if (!muted && freq) {
               const duration = (durationSteps || 1) * 0.25 * spb;
               playNote(freq, playTime, duration, {
                   vol: velocity, 
                   index: 0, 
                   instrument: instrument || 'Piano',
                   dry: dry,
                   numVoices: numVoices
               });
               sendMIDINote(midiState.chordsChannel, getMidi(freq) + (midiState.chordsOctave * 12), normalizeMidiVelocity(velocity), playTime, duration);
            }
        });
    }
}

export function scheduleHarmonies(chordData, step, time) {
    const notes = harmony.buffer.get(step);
    harmony.buffer.delete(step);
    
    if (notes && notes.length > 0) {
        const spb = 60.0 / playback.bpm;

        // If any note in this step is a chord start or movement, 
        // clear previous voices once before scheduling the new ones.
        const starter = notes.find(n => n.isChordStart);
        if (starter) {
            killHarmonyNote(starter.killFade || 0.05);
        }

        // Power-compensation for multiple voices: Scale volume by 1/sqrt(N)
        // Optimization: Count voices without array allocation
        let numVoices = 0;
        for (let i = 0; i < notes.length; i++) {
            if (notes[i].freq || notes[i].midi) numVoices++;
        }
        const polyphonyComp = 1 / Math.sqrt(Math.max(1, numVoices));

        notes.forEach(n => {
            const { freq, velocity, timingOffset, durationSteps, midi, style, slideInterval, slideDuration, vibrato } = n;
            const playTime = time + (timingOffset || 0);
            const m = midi || getMidi(freq);

            if (freq || m) {
                const duration = (durationSteps || 1) * 0.25 * spb;
                const baseVel = velocity * (playback.conductorVelocity || 1.0);
                const finalVel = baseVel * polyphonyComp;
                
                playHarmonyNote(freq || 440, playTime, duration, finalVel, style, m, slideInterval, slideDuration, vibrato);
                sendMIDINote(midiState.harmonyChannel, m + (midiState.harmonyOctave * 12), normalizeMidiVelocity(finalVel), playTime, duration);
                
                if (vizState.enabled && playback.viz) {
                    const { name, octave } = midiToNote(m);
                    playback.drawQueue.push({ type: 'harmony_vis', name, octave, midi: m, time: playTime, duration });
                }
            }
        });
    }
}

export function scheduleGlobalEvent(step, swungTime) {
    const globalTS = TIME_SIGNATURES[arranger.timeSignature] || TIME_SIGNATURES['4/4'];
    const stepInfo = getStepInfo(step, globalTS, arranger.measureMap, TIME_SIGNATURES);
    const ts = TIME_SIGNATURES[stepInfo.tsName] || globalTS;
    
    updateAutoConductor();
    
    // --- NEW: Rhythm Section Mask Calculation ---
    // Extract the snare pattern for the current measure to share with the ensemble
    const spm = getStepsPerMeasure(stepInfo.tsName);
    if (step % spm === 0) {
        let snareMask = 0;
        const snare = groove.instruments.find(i => i.name === 'Snare');
        if (snare) {
            for (let i = 0; i < 16; i++) {
                if (snare.steps[i] > 0) snareMask |= (1 << i);
            }
        }
        if (groove.snareMask !== snareMask) {
            groove.snareMask = snareMask;
            // Immediate sync to worker so harmony module can "hear" the new drum pattern
            syncWorker(ACTIONS.SET_PARAM, { module: 'groove', param: 'snareMask', value: snareMask });
        }
    }

    checkSectionTransition(step, spm);
    
    // MIDI Automation
    if (midiState.enabled && midiState.selectedOutputId && step % 4 === 0) {
        const intensityCC = Math.floor(playback.bandIntensity * 127);
        const soloistTensionCC = Math.floor(soloist.tension * 127);
        
        sendMIDICC(midiState.soloistChannel, 1, soloistTensionCC, swungTime);
        sendMIDICC(midiState.soloistChannel, 11, intensityCC, swungTime);
        sendMIDICC(midiState.chordsChannel, 11, intensityCC, swungTime);
        sendMIDICC(midiState.bassChannel, 11, intensityCC, swungTime);
    }

    const drumStep = step % (groove.measures * spm);
    const t = swungTime + (Math.random() - 0.5) * (groove.humanize / 100) * 0.025;

    if (playback.metronome && stepInfo.isBeatStart) {
        let freq = stepInfo.isMeasureStart ? 1000 : (stepInfo.isGroupStart ? 800 : 600);
        if (ts.beats === 4 && stepInfo.beatIndex === 2 && !stepInfo.isGroupStart) freq = 800;

        const osc = playback.audio.createOscillator();
        const g = playback.audio.createGain();
        osc.connect(g); g.connect(playback.masterGain);
        osc.frequency.setValueAtTime(freq, swungTime);
        g.gain.setValueAtTime(0.15, swungTime);
        g.gain.exponentialRampToValueAtTime(0.001, swungTime + 0.05);
        osc.start(swungTime); osc.stop(swungTime + 0.05);
        osc.onended = () => { g.disconnect(); osc.disconnect(); };
    }

    const feel = groove.genreFeel;
    const straightness = (feel === 'Reggae') ? 0.5 : ((soloist.style === 'neo') ? 0.65 : ((soloist.style === 'blues') ? 0.55 : (soloist.style === 'bossa' ? 0.75 : 0.65)));
    const soloistTime = (playback.unswungNextNoteTime * straightness) + (swungTime * (1.0 - straightness)) + (Math.random() - 0.5) * (groove.humanize / 100) * 0.025;
    
    if (groove.enabled) {
        const isQuarter = stepInfo.isBeatStart;
        const isBackbeat = (ts.beats === 4) ? (stepInfo.beatIndex === 1 || stepInfo.beatIndex === 3) : false;

        if (stepInfo.isBeatStart && playback.visualFlash) {
            playback.drawQueue.push({ 
                type: 'flash', 
                time: swungTime, 
                intensity: (stepInfo.isMeasureStart ? 0.2 : (stepInfo.isGroupStart ? 0.15 : 0.1)), 
                beat: (stepInfo.isMeasureStart ? 1 : 0) 
            });
        }
        
        playback.drawQueue.push({ type: 'drum_vis', step: drumStep, time: swungTime });
        scheduleDrums(drumStep, t, stepInfo.isMeasureStart, isQuarter, isBackbeat, step, stepInfo.isGroupStart);
    }

    const chordData = getChordAtStep(step);
    if (chordData) {
        if (chordData.chord.key && chordData.chord.key !== playback.currentKey) {
            playback.currentKey = chordData.chord.key;
            window.dispatchEvent(new CustomEvent('key-change', { detail: { key: playback.currentKey } }));
        }
        scheduleChordVisuals(chordData, t);
        if (bass.enabled) scheduleBass(chordData, step, t);
        if (soloist.enabled) scheduleSoloist(chordData, step, t, soloistTime);
        if (chords.enabled) scheduleChords(chordData, step, t);
        if (harmony.enabled) scheduleHarmonies(chordData, step, t);
    }
}

export function syncAndFlushWorker(step) {
    const syncData = {
        arranger: { 
            progression: arranger.progression, 
            stepMap: arranger.stepMap, 
            sectionMap: arranger.sectionMap,
            totalSteps: arranger.totalSteps,
            key: arranger.key,
            isMinor: arranger.isMinor,
            timeSignature: arranger.timeSignature,
            grouping: arranger.grouping
        },
        chords: { style: chords.style, octave: chords.octave, density: chords.density, enabled: chords.enabled, volume: chords.volume },
        bass: { style: bass.style, octave: bass.octave, enabled: bass.enabled, lastFreq: bass.lastFreq, volume: bass.volume },
                soloist: { style: soloist.style, octave: soloist.octave, enabled: soloist.enabled, lastFreq: soloist.lastFreq, volume: soloist.volume, doubleStops: soloist.doubleStops },
                harmony: { style: harmony.style, octave: harmony.octave, enabled: harmony.enabled, volume: harmony.volume, complexity: harmony.complexity },
                groove: {
                    genreFeel: groove.genreFeel,
                    lastDrumPreset: groove.lastDrumPreset,
                    enabled: groove.enabled,
                    volume: groove.volume,
                    measures: groove.measures,
                    swing: groove.swing,
                    swingSub: groove.swingSub,
                    instruments: groove.instruments.map(i => ({ name: i.name, steps: [...i.steps], muted: i.muted }))
                },
                playback: { bpm: playback.bpm, bandIntensity: playback.bandIntensity, complexity: playback.complexity, autoIntensity: playback.autoIntensity }
            };
        
            chords.buffer.clear();
            bass.buffer.clear();
            soloist.buffer.clear();
            harmony.buffer.clear();
            groove.fillActive = false;
        
            killAllNotes();    flushWorker(step, syncData);
    restoreGains();
}